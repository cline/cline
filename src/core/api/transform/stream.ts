export type ApiStream = AsyncGenerator<ApiStreamChunk> & { id?: string }
export type ApiStreamChunk = ApiStreamTextChunk | ApiStreamThinkingChunk | ApiStreamUsageChunk | ApiStreamToolCallsChunk

export interface ApiStreamTextChunk {
	type: "text"
	text: string
	id?: string // The response ID associated with this chunk
}

export interface ApiStreamUsageChunk {
	type: "usage"
	inputTokens: number
	outputTokens: number
	cacheWriteTokens?: number
	cacheReadTokens?: number
	thoughtsTokenCount?: number // openrouter
	totalCost?: number // openrouter
	/**
	 * The response ID associated with this chunk
	 */
	id?: string
}

export interface ApiStreamToolCallsChunk {
	type: "tool_calls"
	tool_call: ApiStreamToolCall
	/**
	 * The response ID associated with this chunk
	 */
	id?: string
}

export interface ApiStreamToolCall {
	/**
	 * The response ID associated with this chunk
	 */
	call_id?: string
	// Information about the tool being called
	function: {
		id?: string // The tool call ID
		name?: string
		arguments?: any
	}
}

export interface ApiStreamThinkingChunk {
	type: "reasoning"
	/**
	 * The reasoning text generated by the model.
	 * Redacted reasoning block will have this field set to "[REDACTED]" or an empty string.
	 */
	reasoning: string
	/**
	 * openrouter has various properties that we can pass back unmodified in api requests to preserve reasoning traces
	 * This is also where we store the summary details for OpenAI.
	 */
	details?: unknown
	/**
	 * It's used when sending the thinking block back to the  API.
	 * API expects this in completed form, not as array of deltas.
	 */
	signature?: string
	/**
	 * redacted data
	 */
	redacted_data?: string
	/**
	 * The response ID associated with this chunk
	 */
	id?: string
}
