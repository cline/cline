---
title: "Real-World Examples"
sidebarTitle: "Real-World Examples"
description: "Practical examples and complete working scripts for common hook use cases"
---

This page provides complete, production-ready hook examples that you can use immediately in your projects. Each example includes the full script, explanation, and variations for different scenarios.

## Code Quality Enforcement

### TypeScript-only Project Hook

Prevent creation of JavaScript files in TypeScript projects and enforce proper file extensions.

**Hook:** `PreToolUse`

```bash
#!/usr/bin/env bash
input=$(cat)

# Extract tool information
tool_name=$(echo "$input" | jq -r '.preToolUse.toolName')

# Only process file creation/modification tools
if [[ "$tool_name" != "write_to_file" && "$tool_name" != "replace_in_file" ]]; then
  echo '{"cancel": false}'
  exit 0
fi

# Check if this is a TypeScript project
if [[ ! -f "tsconfig.json" ]]; then
  echo '{"cancel": false}'
  exit 0
fi

# Get the file path
file_path=$(echo "$input" | jq -r '.preToolUse.parameters.path // empty')

if [[ -z "$file_path" ]]; then
  echo '{"cancel": false}'
  exit 0
fi

# Block .js files in TypeScript projects
if [[ "$file_path" == *.js ]]; then
  echo '{"cancel": true, "errorMessage": "JavaScript files (.js) are not allowed in TypeScript projects. Use .ts extension instead."}'
  exit 0
fi

# Block .jsx files, suggest .tsx
if [[ "$file_path" == *.jsx ]]; then
  echo '{"cancel": true, "errorMessage": "JSX files (.jsx) are not allowed in TypeScript projects. Use .tsx extension instead."}'
  exit 0
fi

# Suggest better patterns for certain files
context=""
if [[ "$file_path" == *"component"* ]] && [[ "$file_path" != *.tsx ]]; then
  context="CODING_STANDARDS: React components should use .tsx extension and follow functional component patterns with proper TypeScript interfaces."
elif [[ "$file_path" == *"test"* ]] || [[ "$file_path" == *"spec"* ]]; then
  context="CODING_STANDARDS: Test files should include comprehensive type checking and use jest-dom matchers for better assertions."
fi

if [[ -n "$context" ]]; then
  jq -n --arg ctx "$context" '{"cancel": false, "contextModification": $ctx}'
else
  echo '{"cancel": false}'
fi
```

### Linting Integration Hook

Run linters before file modifications and provide immediate feedback.

**Hook:** `PreToolUse`

```bash
#!/usr/bin/env bash
input=$(cat)

tool_name=$(echo "$input" | jq -r '.preToolUse.toolName')

# Only lint file write operations
if [[ "$tool_name" != "write_to_file" ]]; then
  echo '{"cancel": false}'
  exit 0
fi

file_path=$(echo "$input" | jq -r '.preToolUse.parameters.path // empty')

# Skip non-code files
if [[ ! "$file_path" =~ \.(ts|tsx|js|jsx|py|rs)$ ]]; then
  echo '{"cancel": false}'
  exit 0
fi

# Get file content from the tool parameters  
content=$(echo "$input" | jq -r '.preToolUse.parameters.content // empty')

if [[ -z "$content" ]]; then
  echo '{"cancel": false}'
  exit 0
fi

# Create temporary file for linting
temp_file=$(mktemp)
echo "$content" > "$temp_file"

# Run appropriate linter based on file extension
lint_errors=""
if [[ "$file_path" =~ \.(ts|tsx)$ ]] && command -v eslint > /dev/null; then
  lint_output=$(eslint "$temp_file" --format=json 2>/dev/null || true)
  if [[ "$lint_output" != "[]" ]] && [[ -n "$lint_output" ]]; then
    error_count=$(echo "$lint_output" | jq '.[0].errorCount // 0')
    if (( error_count > 0 )); then
      messages=$(echo "$lint_output" | jq -r '.[0].messages[] | "\(.line):\(.column) \(.message)"')
      lint_errors="ESLint errors found:\n$messages"
    fi
  fi
elif [[ "$file_path" =~ \.py$ ]] && command -v flake8 > /dev/null; then
  lint_output=$(flake8 "$temp_file" 2>/dev/null || true)
  if [[ -n "$lint_output" ]]; then
    lint_errors="Flake8 errors found:\n$lint_output"
  fi
fi

# Cleanup
rm -f "$temp_file"

# Block if linting errors found
if [[ -n "$lint_errors" ]]; then
  error_message="Code quality check failed. Please fix these issues:\n\n$lint_errors"
  jq -n --arg msg "$error_message" '{"cancel": true, "errorMessage": $msg}'
else
  echo '{"cancel": false}'
fi
```

## Security Enforcement

### Secrets Detection Hook

Prevent accidental commit of API keys, passwords, and other sensitive data.

**Hook:** `PreToolUse`

```bash
#!/usr/bin/env bash
input=$(cat)

tool_name=$(echo "$input" | jq -r '.preToolUse.toolName')

# Only check file operations
if [[ "$tool_name" != "write_to_file" ]]; then
  echo '{"cancel": false}'
  exit 0
fi

content=$(echo "$input" | jq -r '.preToolUse.parameters.content // empty')
file_path=$(echo "$input" | jq -r '.preToolUse.parameters.path // empty')

# Skip if no content
if [[ -z "$content" ]]; then
  echo '{"cancel": false}'
  exit 0
fi

# Define secret patterns
declare -a patterns=(
  "(?i)(api[_-]?key|apikey)\s*[:=]\s*['\"][a-zA-Z0-9_-]{10,}['\"]"
  "(?i)(secret|password|pwd)\s*[:=]\s*['\"][^'\"]{8,}['\"]"
  "(?i)token\s*[:=]\s*['\"][a-zA-Z0-9_-]{10,}['\"]"
  "(?i)(aws[_-]?access[_-]?key[_-]?id)\s*[:=]\s*['\"][A-Z0-9]{20}['\"]"
  "(?i)(aws[_-]?secret[_-]?access[_-]?key)\s*[:=]\s*['\"][a-zA-Z0-9+/]{40}['\"]"
  "sk-[a-zA-Z0-9]{20,50}"  # OpenAI API keys
  "ghp_[a-zA-Z0-9]{36}"    # GitHub personal access tokens
)

# Check for secrets
secrets_found=""
for pattern in "${patterns[@]}"; do
  if echo "$content" | grep -qP "$pattern"; then
    match=$(echo "$content" | grep -oP "$pattern" | head -1)
    secrets_found+="- Potential secret detected: ${match:0:20}...\n"
  fi
done

# Check for hardcoded private keys
if echo "$content" | grep -q "BEGIN.*PRIVATE KEY"; then
  secrets_found+="- Private key detected\n"
fi

# Allow secrets in certain safe files
safe_patterns=("\.env\.example$" "\.env\.template$" "/docs/" "/examples/" "\.md$")
is_safe_file=false
for safe_pattern in "${safe_patterns[@]}"; do
  if [[ "$file_path" =~ $safe_pattern ]]; then
    is_safe_file=true
    break
  fi
done

if [[ -n "$secrets_found" ]] && [[ "$is_safe_file" == false ]]; then
  error_message="ðŸ”’ SECURITY ALERT: Potential secrets detected in $file_path

$secrets_found
Please:
1. Use environment variables instead: process.env.API_KEY
2. Add sensitive files to .gitignore
3. Use a secrets management service
4. Consider using .env.example for documentation"

  jq -n --arg msg "$error_message" '{"cancel": true, "errorMessage": $msg}'
else
  echo '{"cancel": false}'
fi
```

### File Access Auditing Hook

Track and log all file access for compliance and security monitoring.

**Hook:** `PostToolUse`

```bash
#!/usr/bin/env bash
input=$(cat)

tool_name=$(echo "$input" | jq -r '.postToolUse.toolName')
success=$(echo "$input" | jq -r '.postToolUse.success')
timestamp=$(echo "$input" | jq -r '.timestamp')
task_id=$(echo "$input" | jq -r '.taskId')
user_id=$(echo "$input" | jq -r '.userId')

# Only log file operations
case "$tool_name" in
  "read_file"|"write_to_file"|"replace_in_file"|"list_files")
    ;;
  *)
    echo '{"cancel": false}'
    exit 0
    ;;
esac

# Extract file path
file_path=""
case "$tool_name" in
  "read_file"|"write_to_file"|"replace_in_file")
    file_path=$(echo "$input" | jq -r '.postToolUse.parameters.path // "unknown"')
    ;;
  "list_files")
    file_path=$(echo "$input" | jq -r '.postToolUse.parameters.path // "unknown"')
    ;;
esac

# Create audit log directory
audit_dir="$HOME/.cline_audit"
mkdir -p "$audit_dir"

# Log to daily audit file
audit_file="$audit_dir/$(date +%Y-%m-%d).log"

# Create detailed log entry
log_entry=$(jq -n \
  --arg timestamp "$timestamp" \
  --arg task_id "$task_id" \
  --arg user_id "$user_id" \
  --arg tool "$tool_name" \
  --arg path "$file_path" \
  --arg success "$success" \
  '{
    timestamp: $timestamp,
    task_id: $task_id, 
    user_id: $user_id,
    operation: $tool,
    file_path: $path,
    success: ($success == "true"),
    workspace: env.PWD
  }')

echo "$log_entry" >> "$audit_file"

# Alert on sensitive file access
sensitive_patterns=("\.env$" "\.key$" "\.pem$" "\.p12$" "config/" "secrets/")
is_sensitive=false
for pattern in "${sensitive_patterns[@]}"; do
  if [[ "$file_path" =~ $pattern ]]; then
    is_sensitive=true
    break
  fi
done

if [[ "$is_sensitive" == true ]]; then
  context="SECURITY_AUDIT: Sensitive file accessed: $file_path. This operation has been logged for compliance."
  jq -n --arg ctx "$context" '{"cancel": false, "contextModification": $ctx}'
else
  echo '{"cancel": false}'
fi
```

## Development Workflow Integration

### Git Integration Hook

Automatically create meaningful commit messages and enforce branch naming conventions.

**Hook:** `PostToolUse`

```bash
#!/usr/bin/env bash
input=$(cat)

tool_name=$(echo "$input" | jq -r '.postToolUse.toolName')
success=$(echo "$input" | jq -r '.postToolUse.success')

# Only process successful file modifications
if [[ "$success" != "true" ]] || [[ "$tool_name" != "write_to_file" && "$tool_name" != "replace_in_file" ]]; then
  echo '{"cancel": false}'
  exit 0
fi

# Check if we're in a git repository
if ! git rev-parse --git-dir > /dev/null 2>&1; then
  echo '{"cancel": false}'
  exit 0
fi

file_path=$(echo "$input" | jq -r '.postToolUse.parameters.path // empty')

# Skip if no file path
if [[ -z "$file_path" ]]; then
  echo '{"cancel": false}'
  exit 0
fi

# Check current branch
current_branch=$(git branch --show-current 2>/dev/null || echo "main")

# Suggest better branch naming for certain patterns
context=""
if [[ "$file_path" == *"component"* ]] && [[ "$current_branch" == "main" || "$current_branch" == "master" ]]; then
  context="GIT_WORKFLOW: Consider creating a feature branch for component changes: git checkout -b feature/add-${file_path##*/}"
elif [[ "$file_path" == *"test"* ]] || [[ "$file_path" == *"spec"* ]]; then
  if [[ "$current_branch" == "main" || "$current_branch" == "master" ]]; then
    context="GIT_WORKFLOW: Consider creating a test branch: git checkout -b test/add-${file_path##*/}-tests"
  fi
elif [[ "$file_path" == *"fix"* ]] || [[ "$file_path" == *"bug"* ]]; then
  if [[ "$current_branch" == "main" || "$current_branch" == "master" ]]; then
    context="GIT_WORKFLOW: Consider creating a bugfix branch: git checkout -b bugfix/fix-issue-description"
  fi
fi

# Stage the file automatically (optional - remove if you prefer manual staging)
# git add "$file_path" 2>/dev/null || true

# Add context about staging
if [[ -n "$context" ]]; then
  context="$context After your changes are complete, use 'git add $file_path' to stage for commit."
else
  context="GIT_WORKFLOW: File modified: $file_path. Use 'git add $file_path' to stage when ready to commit."
fi

jq -n --arg ctx "$context" '{"cancel": false, "contextModification": $ctx}'
```

### CI/CD Trigger Hook

Notify CI/CD systems and trigger builds when certain files are modified.

**Hook:** `PostToolUse`

```bash
#!/usr/bin/env bash
input=$(cat)

tool_name=$(echo "$input" | jq -r '.postToolUse.toolName')
success=$(echo "$input" | jq -r '.postToolUse.success')

# Only process successful file operations
if [[ "$success" != "true" ]] || [[ "$tool_name" != "write_to_file" && "$tool_name" != "replace_in_file" ]]; then
  echo '{"cancel": false}'
  exit 0
fi

file_path=$(echo "$input" | jq -r '.postToolUse.parameters.path // empty')

# Define trigger patterns for different workflows
declare -A triggers=(
  ["package\\.json|yarn\\.lock|package-lock\\.json"]="dependencies"
  ["\\.github/workflows/.*\\.ya?ml"]="workflow"
  ["Dockerfile|docker-compose\\.ya?ml"]="docker"
  ["src/.*\\.(ts|tsx|js|jsx)"]="frontend"
  ["api/.*\\.(ts|js|py)"]="backend"
  ["\\.(test|spec)\\.(ts|tsx|js|jsx|py)"]="tests"
)

# Check which workflows should be triggered
triggered_workflows=""
for pattern in "${!triggers[@]}"; do
  if [[ "$file_path" =~ $pattern ]]; then
    workflow_type="${triggers[$pattern]}"
    triggered_workflows+="$workflow_type "
  fi
done

if [[ -n "$triggered_workflows" ]]; then
  # Create webhook payload (example - adjust URL and payload as needed)
  webhook_url="${CI_WEBHOOK_URL:-}"
  
  if [[ -n "$webhook_url" ]]; then
    payload=$(jq -n \
      --arg file "$file_path" \
      --arg workflows "$triggered_workflows" \
      --arg timestamp "$(date -Iseconds)" \
      '{
        event: "file_modified",
        file_path: $file,
        triggered_workflows: ($workflows | split(" ") | map(select(length > 0))),
        timestamp: $timestamp,
        source: "cline_hook"
      }')
    
    # Trigger webhook asynchronously (don't block on network issues)
    curl -X POST \
      -H "Content-Type: application/json" \
      -d "$payload" \
      "$webhook_url" \
      --max-time 5 \
      --silent \
      > /dev/null 2>&1 &
  fi
  
  context="CI_CD: File modification may trigger workflows: $triggered_workflows. Check your CI/CD dashboard for build status."
  jq -n --arg ctx "$context" '{"cancel": false, "contextModification": $ctx}'
else
  echo '{"cancel": false}'
fi
```

## Performance Monitoring

### Operation Performance Tracker

Monitor and log slow operations to identify performance bottlenecks.

**Hook:** `PostToolUse`

```bash
#!/usr/bin/env bash
input=$(cat)

tool_name=$(echo "$input" | jq -r '.postToolUse.toolName')
execution_time=$(echo "$input" | jq -r '.postToolUse.executionTimeMs // 0')
success=$(echo "$input" | jq -r '.postToolUse.success')
timestamp=$(echo "$input" | jq -r '.timestamp')

# Performance thresholds (in milliseconds)
SLOW_THRESHOLD=2000
VERY_SLOW_THRESHOLD=5000

# Create performance log directory
perf_dir="$HOME/.cline_performance"
mkdir -p "$perf_dir"

# Log all operations to daily performance file
perf_file="$perf_dir/$(date +%Y-%m-%d).json"

# Create performance log entry
log_entry=$(jq -n \
  --arg timestamp "$timestamp" \
  --arg tool "$tool_name" \
  --arg duration "$execution_time" \
  --arg success "$success" \
  '{
    timestamp: $timestamp,
    tool: $tool,
    duration_ms: ($duration | tonumber),
    success: ($success == "true"),
    workspace: env.PWD
  }')

echo "$log_entry" >> "$perf_file"

# Generate context based on performance
context=""
if (( execution_time > VERY_SLOW_THRESHOLD )); then
  context="PERFORMANCE_ALERT: Very slow operation detected! $tool_name took ${execution_time}ms. Consider optimizing or investigating system resources."
elif (( execution_time > SLOW_THRESHOLD )); then
  context="PERFORMANCE_WARNING: Slow operation - $tool_name took ${execution_time}ms. Monitor for patterns."
fi

# Calculate daily statistics (simple version)
if [[ "$tool_name" == "execute_command" ]] && (( execution_time > SLOW_THRESHOLD )); then
  # For slow commands, add specific guidance
  context+=" For slow commands, consider using background processes or breaking into smaller steps."
fi

if [[ -n "$context" ]]; then
  jq -n --arg ctx "$context" '{"cancel": false, "contextModification": $ctx}'
else
  echo '{"cancel": false}'
fi
```

## External Integrations

### Slack Notifications Hook

Send notifications to Slack for important events and errors.

**Hook:** `PostToolUse`

```bash
#!/usr/bin/env bash
input=$(cat)

tool_name=$(echo "$input" | jq -r '.postToolUse.toolName')
success=$(echo "$input" | jq -r '.postToolUse.success')
result=$(echo "$input" | jq -r '.postToolUse.result // empty')

# Only notify on significant events or errors
notify_tools=("execute_command" "browser_action")
should_notify=false

for notify_tool in "${notify_tools[@]}"; do
  if [[ "$tool_name" == "$notify_tool" ]]; then
    should_notify=true
    break
  fi
done

# Also notify on any failures
if [[ "$success" == "false" ]]; then
  should_notify=true
fi

if [[ "$should_notify" != "true" ]]; then
  echo '{"cancel": false}'
  exit 0
fi

# Get Slack webhook URL from environment
slack_webhook="${SLACK_WEBHOOK_URL:-}"

if [[ -z "$slack_webhook" ]]; then
  echo '{"cancel": false}'
  exit 0
fi

# Determine message color and content
if [[ "$success" == "false" ]]; then
  color="danger"
  status_icon="ðŸš¨"
  title="Cline Operation Failed"
else
  color="good"
  status_icon="âœ…"
  title="Cline Operation Completed"
fi

# Create Slack message
user_id=$(echo "$input" | jq -r '.userId')
task_id=$(echo "$input" | jq -r '.taskId')
workspace=$(basename "$PWD")

# Truncate long results
truncated_result="$result"
if [[ ${#result} -gt 200 ]]; then
  truncated_result="${result:0:200}..."
fi

slack_payload=$(jq -n \
  --arg color "$color" \
  --arg title "$title" \
  --arg icon "$status_icon" \
  --arg tool "$tool_name" \
  --arg workspace "$workspace" \
  --arg result "$truncated_result" \
  --arg user "$user_id" \
  --arg task "$task_id" \
  '{
    attachments: [{
      color: $color,
      title: ($icon + " " + $title),
      fields: [
        {title: "Tool", value: $tool, short: true},
        {title: "Workspace", value: $workspace, short: true},
        {title: "User", value: $user, short: true},
        {title: "Task ID", value: $task, short: true},
        {title: "Result", value: $result, short: false}
      ],
      ts: now
    }]
  }')

# Send to Slack asynchronously
curl -X POST \
  -H "Content-Type: application/json" \
  -d "$slack_payload" \
  "$slack_webhook" \
  --max-time 5 \
  --silent \
  > /dev/null 2>&1 &

echo '{"cancel": false}'
```

### Jira Integration Hook

Create Jira tickets for errors and track development progress.

**Hook:** `TaskStart`

```bash
#!/usr/bin/env bash
input=$(cat)

initial_task=$(echo "$input" | jq -r '.taskStart.taskMetadata.initialTask')
task_id=$(echo "$input" | jq -r '.taskId')

# Get Jira configuration from environment
jira_url="${JIRA_URL:-}"
jira_user="${JIRA_USER:-}"
jira_token="${JIRA_TOKEN:-}"
jira_project="${JIRA_PROJECT:-DEV}"

if [[ -z "$jira_url" || -z "$jira_user" || -z "$jira_token" ]]; then
  echo '{"cancel": false}'
  exit 0
fi

# Determine if this looks like a bug fix or feature
issue_type="Task"
priority="Medium"

if echo "$initial_task" | grep -qi "bug\|fix\|error\|issue\|problem"; then
  issue_type="Bug"
  priority="High"
elif echo "$initial_task" | grep -qi "feature\|add\|implement\|create"; then
  issue_type="Story"
  priority="Medium"
fi

# Create Jira ticket payload
jira_payload=$(jq -n \
  --arg project "$jira_project" \
  --arg summary "Cline Task: $(echo "$initial_task" | head -c 100)" \
  --arg description "Automated task created from Cline:

**Task ID:** $task_id
**Full Description:** $initial_task
**Workspace:** $(basename "$PWD")
**Created:** $(date -Iseconds)

This ticket tracks development work performed by Cline AI assistant." \
  --arg issue_type "$issue_type" \
  --arg priority "$priority" \
  '{
    fields: {
      project: {key: $project},
      summary: $summary,
      description: $description,
      issuetype: {name: $issue_type},
      priority: {name: $priority},
      labels: ["cline", "automated", "ai-generated"]
    }
  }')

# Create Jira ticket
jira_response=$(curl -X POST \
  -H "Content-Type: application/json" \
  -u "$jira_user:$jira_token" \
  -d "$jira_payload" \
  "$jira_url/rest/api/2/issue/" \
  --max-time 10 \
  --silent)

# Extract ticket key if successful
ticket_key=$(echo "$jira_response" | jq -r '.key // empty' 2>/dev/null)

if [[ -n "$ticket_key" ]]; then
  context="JIRA_INTEGRATION: Created ticket $ticket_key for this task. Visit $jira_url/browse/$ticket_key to track progress."
  jq -n --arg ctx "$context" '{"cancel": false, "contextModification": $ctx}'
else
  echo '{"cancel": false}'
fi
```

## Task Lifecycle Management

### Task Completion Tracking Hook

Track successful task completions and generate completion reports.

**Hook:** `TaskComplete`

```bash
#!/usr/bin/env bash
input=$(cat)

# Extract task metadata using proper API field paths
task_id=$(echo "$input" | jq -r '.taskId')
ulid=$(echo "$input" | jq -r '.taskComplete.taskMetadata.ulid // "unknown"')
completion_time=$(echo "$input" | jq -r '.timestamp')

# Create completion report directory (with proper path validation)
reports_dir="$HOME/.cline_reports"
if [[ ! -d "$(dirname "$reports_dir")" ]]; then
  echo '{"cancel": false, "errorMessage": "Cannot access home directory"}' 
  exit 0
fi
mkdir -p "$reports_dir" || exit 0

# Generate safe report filename
safe_task_id=$(echo "$task_id" | tr -cd '[:alnum:]_-' | head -c 50)
report_file="$reports_dir/completion_$(date +%Y%m%d_%H%M%S)_${safe_task_id}.md"

# Generate completion report with available data
cat > "$report_file" << EOF
# Cline Task Completion Report

**Task ID:** $task_id
**ULID:** $ulid
**Completed:** $(date -Iseconds)
**Completion Time:** $completion_time

## Workspace Information
- **Project:** $(basename "$PWD")
- **Git Branch:** $(git branch --show-current 2>/dev/null || echo "No git repository")
- **Git Status:** $(git status --porcelain 2>/dev/null | wc -l || echo "0") modified files

## Completion Status
âœ… Task completed successfully

## Next Steps
- Review changes made during this task
- Consider committing changes if appropriate
- Run tests to verify functionality
EOF

# Send completion notification if webhook configured (async with timeout)
webhook_url="${COMPLETION_WEBHOOK_URL:-}"
if [[ -n "$webhook_url" ]]; then
  payload=$(jq -n \
    --arg task_id "$task_id" \
    --arg ulid "$ulid" \
    --arg workspace "$(basename "$PWD")" \
    --arg timestamp "$completion_time" \
    '{
      event: "task_completed",
      task_id: $task_id,
      ulid: $ulid,
      workspace: $workspace,
      timestamp: $timestamp
    }')
  
  # Send notification in background with timeout
  (curl -X POST \
    -H "Content-Type: application/json" \
    -d "$payload" \
    "$webhook_url" \
    --max-time 5 \
    --silent > /dev/null 2>&1) &
fi

# Provide completion summary
context="TASK_COMPLETED: âœ… Task $task_id finished successfully (ULID: $ulid). Report saved to: $(basename "$report_file")"

jq -n --arg ctx "$context" '{"cancel": false, "contextModification": $ctx}'
```

### Task Cancellation Handler Hook  

Handle task cancellations gracefully with cleanup and logging.

**Hook:** `TaskCancel`

```bash
#!/usr/bin/env bash
input=$(cat)

# Extract task metadata using proper API field paths
task_id=$(echo "$input" | jq -r '.taskId')
ulid=$(echo "$input" | jq -r '.taskCancel.taskMetadata.ulid // "unknown"')
cancellation_timestamp=$(echo "$input" | jq -r '.timestamp')

# Create cancellation log directory (with proper path validation)
cancel_dir="$HOME/.cline_cancellations"
if [[ ! -d "$(dirname "$cancel_dir")" ]]; then
  echo '{"cancel": false, "errorMessage": "Cannot access home directory"}'
  exit 0
fi
mkdir -p "$cancel_dir" || exit 0

# Log cancellation details with available data
cancel_log="$cancel_dir/$(date +%Y-%m-%d).log"

cancel_entry=$(jq -n \
  --arg timestamp "$cancellation_timestamp" \
  --arg task_id "$task_id" \
  --arg ulid "$ulid" \
  --arg workspace "$(basename "$PWD")" \
  '{
    timestamp: $timestamp,
    task_id: $task_id,
    ulid: $ulid,
    event: "task_canceled",
    workspace: $workspace
  }')

echo "$cancel_entry" >> "$cancel_log"

# Clean up temporary files created during this task (with safe patterns)
temp_patterns=("*.tmp" "*.temp" ".cline_${task_id}_*")
cleaned_files=0

for pattern in "${temp_patterns[@]}"; do
  # Use find to safely handle patterns and avoid shell expansion issues
  if find . -maxdepth 1 -name "$pattern" -type f 2>/dev/null | grep -q .; then
    find . -maxdepth 1 -name "$pattern" -type f -exec rm -f {} + 2>/dev/null || true
    cleaned_files=$((cleaned_files + $(find . -maxdepth 1 -name "$pattern" -type f 2>/dev/null | wc -l)))
  fi
done

# Handle git repository cleanup (only if safe to do so)
context="TASK_CANCELED: Task $task_id (ULID: $ulid) was canceled."

if git rev-parse --git-dir > /dev/null 2>&1; then
  uncommitted_count=$(git status --porcelain | wc -l)
  if (( uncommitted_count > 0 )); then
    # Only offer to stash if there are changes and it's safe
    context+=" Found $uncommitted_count uncommitted changes."
  fi
fi

if (( cleaned_files > 0 )); then
  context+=" Cleaned up $cleaned_files temporary files."
fi

# Optional: Send cancellation alert (async with proper timeout)
cancel_webhook="${CANCEL_WEBHOOK_URL:-}"
if [[ -n "$cancel_webhook" ]]; then
  payload=$(jq -n \
    --arg task_id "$task_id" \
    --arg ulid "$ulid" \
    --arg timestamp "$cancellation_timestamp" \
    --arg workspace "$(basename "$PWD")" \
    '{
      event: "task_canceled",
      task_id: $task_id,
      ulid: $ulid,
      timestamp: $timestamp,
      workspace: $workspace
    }')
  
  # Send notification in background with timeout
  (curl -X POST \
    -H "Content-Type: application/json" \
    -d "$payload" \
    "$cancel_webhook" \
    --max-time 3 \
    --silent > /dev/null 2>&1) &
fi

jq -n --arg ctx "$context" '{"cancel": false, "contextModification": $ctx}'
```

### Task Resume Preparation Hook

Prepare environment and validate state when resuming tasks.

**Hook:** `TaskResume`

```bash
#!/usr/bin/env bash
input=$(cat)

# Extract task metadata and previous state using proper API field paths
task_id=$(echo "$input" | jq -r '.taskId')
ulid=$(echo "$input" | jq -r '.taskResume.taskMetadata.ulid // "unknown"')
last_message_ts=$(echo "$input" | jq -r '.taskResume.previousState.lastMessageTs // "unknown"')
message_count=$(echo "$input" | jq -r '.taskResume.previousState.messageCount // "0"')
history_deleted=$(echo "$input" | jq -r '.taskResume.previousState.conversationHistoryDeleted // "false"')

# Calculate approximate pause duration from last message timestamp (if available)
pause_info=""
if [[ "$last_message_ts" != "unknown" && "$last_message_ts" != "null" ]]; then
  # Try to calculate time since last message (simplified)
  current_time=$(date +%s)
  if command -v gdate > /dev/null; then
    last_time=$(gdate -d "$last_message_ts" +%s 2>/dev/null || echo "$current_time")
  else
    last_time=$(date -j -f "%Y-%m-%dT%H:%M:%SZ" "$last_message_ts" +%s 2>/dev/null || echo "$current_time")
  fi
  pause_seconds=$((current_time - last_time))
  if (( pause_seconds > 60 )); then
    pause_minutes=$((pause_seconds / 60))
    pause_info="paused for approximately $pause_minutes minutes"
  fi
fi

# Validate workspace state
workspace_issues=""

# Check if git repository state changed
if git rev-parse --git-dir > /dev/null 2>&1; then
  current_branch=$(git branch --show-current 2>/dev/null || echo "")
  uncommitted_changes=$(git status --porcelain | wc -l)
  
  if (( uncommitted_changes > 5 )); then
    workspace_issues+="âš ï¸ Many uncommitted changes detected ($uncommitted_changes files). "
  fi
  
  # Check if branch switched (using safe task-specific tracking)
  expected_branch_file=".cline_task_${task_id}_branch"
  if [[ -f "$expected_branch_file" ]]; then
    expected_branch=$(cat "$expected_branch_file" | tr -d '\n\r')
    if [[ "$current_branch" != "$expected_branch" ]]; then
      workspace_issues+="âš ï¸ Git branch changed from '$expected_branch' to '$current_branch'. "
    fi
  else
    # Store current branch for future reference (safely)
    if [[ -n "$current_branch" ]]; then
      echo "$current_branch" > "$expected_branch_file"
    fi
  fi
fi

# Check for dependency changes (with proper validation)
dependency_issues=""
if [[ -f "package.json" ]]; then
  hash_file=".cline_task_${task_id}_package_hash"
  if [[ -f "$hash_file" ]]; then
    stored_hash=$(cat "$hash_file" | tr -d '\n\r')
    current_hash=$(shasum package.json | cut -d' ' -f1 2>/dev/null || echo "unknown")
    if [[ "$stored_hash" != "$current_hash" && "$current_hash" != "unknown" ]]; then
      dependency_issues+="âš ï¸ package.json modified during pause - dependencies may have changed. Consider running npm install. "
    fi
  else
    # Store current hash for future reference
    if command -v shasum > /dev/null; then
      shasum package.json | cut -d' ' -f1 > "$hash_file" 2>/dev/null || true
    fi
  fi
fi

# Check system resources (with safer calculation)
available_space=$(df . 2>/dev/null | tail -1 | awk '{print $4}' || echo "unknown")
if [[ "$available_space" != "unknown" ]] && (( available_space < 1000000 )); then  # Less than ~1GB
  gb_available=$(echo "$available_space" | awk '{printf "%.1f", $1/1000000}')
  workspace_issues+="âš ï¸ Low disk space (${gb_available}GB available). "
fi

# Create resume context with available information
context="TASK_RESUMED: Task $task_id (ULID: $ulid) resuming"
if [[ -n "$pause_info" ]]; then
  context+=" ($pause_info)"
fi
context+=". Previous message count: $message_count."

if [[ "$history_deleted" == "true" ]]; then
  context+=" Note: Some conversation history was previously compacted."
fi

if [[ -n "$workspace_issues" ]]; then
  context+=" WORKSPACE_CHANGES: $workspace_issues"
fi

if [[ -n "$dependency_issues" ]]; then
  context+=" DEPENDENCY_CHANGES: $dependency_issues"
fi

# Log resume event (with proper path validation)
resume_log="$HOME/.cline_resumes/$(date +%Y-%m-%d).log"
if [[ -d "$HOME" ]]; then
  mkdir -p "$(dirname "$resume_log")" 2>/dev/null || true
  
  resume_entry=$(jq -n \
    --arg timestamp "$(date -Iseconds)" \
    --arg task_id "$task_id" \
    --arg ulid "$ulid" \
    --arg last_msg_ts "$last_message_ts" \
    --arg msg_count "$message_count" \
    --arg history_deleted "$history_deleted" \
    --arg workspace_issues "$workspace_issues" \
    '{
      timestamp: $timestamp,
      task_id: $task_id,
      ulid: $ulid,
      last_message_timestamp: $last_msg_ts,
      previous_message_count: ($msg_count | tonumber),
      conversation_history_deleted: ($history_deleted == "true"),
      workspace_issues: $workspace_issues,
      workspace: env.PWD
    }')
  
  echo "$resume_entry" >> "$resume_log" 2>/dev/null || true
fi

jq -n --arg ctx "$context" '{"cancel": false, "contextModification": $ctx}'
```

## Memory and Context Management

### Pre-Compact Context Preservation Hook

Backup important conversation context before history compaction.

**Hook:** `PreCompact`

```bash
#!/usr/bin/env bash
input=$(cat)

task_id=$(echo "$input" | jq -r '.taskId')
messages_to_remove=$(echo "$input" | jq -r '.preCompact.messagesToRemove // 0')
total_messages=$(echo "$input" | jq -r '.preCompact.totalMessages // 0')
compaction_trigger=$(echo "$input" | jq -r '.preCompact.trigger // "context_limit"')

# Create context backup directory
backup_dir="$HOME/.cline_context_backups"
mkdir -p "$backup_dir"

# Create dated backup file
backup_file="$backup_dir/${task_id}_$(date +%Y%m%d_%H%M%S).json"

# Extract conversation history for backup
conversation_history=$(echo "$input" | jq '.preCompact.conversationHistory // []')

# Create comprehensive backup
backup_data=$(jq -n \
  --arg task_id "$task_id" \
  --arg timestamp "$(date -Iseconds)" \
  --arg trigger "$compaction_trigger" \
  --arg messages_removed "$messages_to_remove" \
  --arg total_messages "$total_messages" \
  --argjson history "$conversation_history" \
  '{
    task_id: $task_id,
    backup_timestamp: $timestamp,
    compaction_trigger: $trigger,
    messages_removed: ($messages_removed | tonumber),
    total_messages: ($total_messages | tonumber),
    workspace: env.PWD,
    git_commit: null,
    conversation_history: $history
  }')

# Add git commit hash if available
if git rev-parse --git-dir > /dev/null 2>&1; then
  git_hash=$(git rev-parse HEAD 2>/dev/null || echo "no-commit")
  backup_data=$(echo "$backup_data" | jq --arg hash "$git_hash" '.git_commit = $hash')
fi

echo "$backup_data" > "$backup_file"

# Compress older backups (keep last 5 uncompressed)
find "$backup_dir" -name "${task_id}_*.json" -type f | sort -r | tail -n +6 | while read old_backup; do
  if [[ ! -f "${old_backup}.gz" ]]; then
    gzip "$old_backup" 2>/dev/null || true
  fi
done

# Extract key information for context preservation
important_context=""

# Look for error patterns in history
if echo "$conversation_history" | jq -r '.[] | select(.type == "error") | .content' | grep -q .; then
  error_count=$(echo "$conversation_history" | jq '[.[] | select(.type == "error")] | length')
  important_context+="Previous errors encountered: $error_count. "
fi

# Look for successful patterns
if echo "$conversation_history" | jq -r '.[] | select(.type == "success") | .content' | grep -q .; then
  success_patterns=$(echo "$conversation_history" | jq -r '[.[] | select(.type == "success")] | length')
  important_context+="Successful operations: $success_patterns. "
fi

# Create context summary for AI
context="CONTEXT_COMPACTION: Removing $messages_to_remove of $total_messages messages due to $compaction_trigger. Backup saved to: $(basename "$backup_file"). "

if [[ -n "$important_context" ]]; then
  context+="PRESERVED_CONTEXT: $important_context"
fi

# Optional: Send to external storage
external_backup_webhook="${CONTEXT_BACKUP_WEBHOOK:-}"
if [[ -n "$external_backup_webhook" ]]; then
  curl -X POST \
    -H "Content-Type: application/json" \
    -d "$backup_data" \
    "$external_backup_webhook" \
    --max-time 10 \
    --silent > /dev/null 2>&1 &
fi

jq -n --arg ctx "$context" '{"cancel": false, "contextModification": $ctx}'
```

### User Input Validation Hook

Validate and enhance user prompts before processing.

**Hook:** `UserPromptSubmit`

```bash
#!/usr/bin/env bash
input=$(cat)

user_prompt=$(echo "$input" | jq -r '.userPromptSubmit.prompt')
prompt_type=$(echo "$input" | jq -r '.userPromptSubmit.type // "text"')
task_id=$(echo "$input" | jq -r '.taskId')
user_id=$(echo "$input" | jq -r '.userId')

# Log user activity for analytics
activity_log="$HOME/.cline_user_activity/$(date +%Y-%m-%d).log"
mkdir -p "$(dirname "$activity_log")"

activity_entry=$(jq -n \
  --arg timestamp "$(date -Iseconds)" \
  --arg task_id "$task_id" \
  --arg user_id "$user_id" \
  --arg prompt_length "${#user_prompt}" \
  --arg prompt_type "$prompt_type" \
  '{
    timestamp: $timestamp,
    task_id: $task_id,
    user_id: $user_id,
    prompt_length: ($prompt_length | tonumber),
    prompt_type: $prompt_type,
    workspace: env.PWD
  }')

echo "$activity_entry" >> "$activity_log"

# Analyze prompt for potential issues
context_modifications=""
cancel_request=false

# Check for potentially harmful requests
harmful_patterns=("rm -rf" "delete" "remove all" "format.*drive" "sudo.*passwd")
for pattern in "${harmful_patterns[@]}"; do
  if echo "$user_prompt" | grep -qi "$pattern"; then
    cancel_request=true
    error_message="ðŸš¨ SAFETY ALERT: Potentially harmful command detected in prompt. Please review your request and ensure it's safe to execute."
    break
  fi
done

# Enhance prompts with helpful context
if [[ "$cancel_request" == false ]]; then
  # Add project context if user asks about files
  if echo "$user_prompt" | grep -qi "file\|directory\|folder" && [[ ! "$user_prompt" == *"context:"* ]]; then
    if [[ -f "package.json" ]]; then
      project_name=$(jq -r '.name // "unknown"' package.json 2>/dev/null)
      context_modifications+="PROJECT_CONTEXT: Working in Node.js project '$project_name'. "
    elif [[ -f "requirements.txt" ]] || [[ -f "setup.py" ]]; then
      context_modifications+="PROJECT_CONTEXT: Working in Python project. "
    elif [[ -f "Cargo.toml" ]]; then
      project_name=$(grep '^name = ' Cargo.toml | cut -d'"' -f2 2>/dev/null || echo "unknown")
      context_modifications+="PROJECT_CONTEXT: Working in Rust project '$project_name'. "
    fi
  fi
  
  # Add git context for version control related requests
  if echo "$user_prompt" | grep -qi "git\|commit\|branch\|merge" && git rev-parse --git-dir > /dev/null 2>&1; then
    current_branch=$(git branch --show-current 2>/dev/null)
    uncommitted=$(git status --porcelain | wc -l)
    context_modifications+="GIT_CONTEXT: On branch '$current_branch' with $uncommitted uncommitted changes. "
  fi
  
  # Suggest specific tools for common requests
  if echo "$user_prompt" | grep -qi "search.*code\|find.*function"; then
    context_modifications+="TOOL_SUGGESTION: Consider using search_files tool for code exploration. "
  elif echo "$user_prompt" | grep -qi "test.*website\|check.*browser"; then
    context_modifications+="TOOL_SUGGESTION: Consider using browser_action tool for web testing. "
  fi
  
  # Flag overly broad requests
  if (( ${#user_prompt} < 20 )) && echo "$user_prompt" | grep -qi "^(fix|update|change|modify)"; then
    context_modifications+="CLARITY_NEEDED: Request seems broad. Consider providing more specific details about what needs to be fixed/updated. "
  fi
fi

# Return appropriate response
if [[ "$cancel_request" == true ]]; then
  jq -n --arg msg "$error_message" '{"cancel": true, "errorMessage": $msg}'
else
  if [[ -n "$context_modifications" ]]; then
    jq -n --arg ctx "$context_modifications" '{"cancel": false, "contextModification": $ctx}'
  else
    echo '{"cancel": false}'
  fi
fi
```

## Usage Tips

### Running Multiple Hooks

You can use multiple hooks together by creating separate files for each hook type:

```bash
# Create hooks directory
mkdir -p .clinerules/hooks

# Create multiple hooks
touch .clinerules/hooks/PreToolUse
touch .clinerules/hooks/PostToolUse
touch .clinerules/hooks/TaskStart

# Make them executable
chmod +x .clinerules/hooks/*
```

### Environment Configuration

Set up environment variables for external integrations:

```bash
# Add to your .bashrc or .zshrc
export SLACK_WEBHOOK_URL="https://hooks.slack.com/services/..."
export JIRA_URL="https://yourcompany.atlassian.net"
export JIRA_USER="your-email@company.com"
export JIRA_TOKEN="your-api-token"
export CI_WEBHOOK_URL="https://your-ci-system.com/hooks/cline"
```

### Testing Your Hooks

Test hooks manually by simulating their input:

```bash
# Test a PreToolUse hook
echo '{
  "clineVersion": "1.0.0",
  "hookName": "PreToolUse",
  "timestamp": "2024-01-01T12:00:00Z",
  "taskId": "test",
  "workspaceRoots": ["/path/to/workspace"],
  "userId": "test-user",
  "preToolUse": {
    "toolName": "write_to_file",
    "parameters": {
      "path": "test.js",
      "content": "console.log(\"test\");"
    }
  }
}' | .clinerules/hooks/PreToolUse
```

These examples provide a solid foundation for implementing hooks in your development workflow. Customize them based on your specific needs, tools, and integrations.
