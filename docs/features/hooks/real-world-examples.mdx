---
title: "Real-World Examples"
sidebarTitle: "Real-World Examples"
description: "Practical examples and complete working scripts for common hook use cases"
---

This page provides complete, production-ready hook examples that you can use immediately in your projects. Each example includes the full script, explanation, and variations for different scenarios.

## Code Quality Enforcement

### TypeScript-only Project Hook

Prevent creation of JavaScript files in TypeScript projects and enforce proper file extensions.

**Hook:** `PreToolUse`

```bash
#!/usr/bin/env bash
input=$(cat)

# Extract tool information
tool_name=$(echo "$input" | jq -r '.preToolUse.toolName')

# Only process file creation/modification tools
if [[ "$tool_name" != "write_to_file" && "$tool_name" != "replace_in_file" ]]; then
  echo '{"cancel": false}'
  exit 0
fi

# Check if this is a TypeScript project
if [[ ! -f "tsconfig.json" ]]; then
  echo '{"cancel": false}'
  exit 0
fi

# Get the file path
file_path=$(echo "$input" | jq -r '.preToolUse.parameters.path // empty')

if [[ -z "$file_path" ]]; then
  echo '{"cancel": false}'
  exit 0
fi

# Block .js files in TypeScript projects
if [[ "$file_path" == *.js ]]; then
  echo '{"cancel": true, "errorMessage": "JavaScript files (.js) are not allowed in TypeScript projects. Use .ts extension instead."}'
  exit 0
fi

# Block .jsx files, suggest .tsx
if [[ "$file_path" == *.jsx ]]; then
  echo '{"cancel": true, "errorMessage": "JSX files (.jsx) are not allowed in TypeScript projects. Use .tsx extension instead."}'
  exit 0
fi

# Suggest better patterns for certain files
context=""
if [[ "$file_path" == *"component"* ]] && [[ "$file_path" != *.tsx ]]; then
  context="CODING_STANDARDS: React components should use .tsx extension and follow functional component patterns with proper TypeScript interfaces."
elif [[ "$file_path" == *"test"* ]] || [[ "$file_path" == *"spec"* ]]; then
  context="CODING_STANDARDS: Test files should include comprehensive type checking and use jest-dom matchers for better assertions."
fi

if [[ -n "$context" ]]; then
  jq -n --arg ctx "$context" '{"cancel": false, "contextModification": $ctx}'
else
  echo '{"cancel": false}'
fi
```

### Linting Integration Hook

Run linters before file modifications and provide immediate feedback.

**Hook:** `PreToolUse`

```bash
#!/usr/bin/env bash
input=$(cat)

tool_name=$(echo "$input" | jq -r '.preToolUse.toolName')

# Only lint file write operations
if [[ "$tool_name" != "write_to_file" ]]; then
  echo '{"cancel": false}'
  exit 0
fi

file_path=$(echo "$input" | jq -r '.preToolUse.parameters.path // empty')

# Skip non-code files
if [[ ! "$file_path" =~ \.(ts|tsx|js|jsx|py|rs)$ ]]; then
  echo '{"cancel": false}'
  exit 0
fi

# Get file content from the tool parameters  
content=$(echo "$input" | jq -r '.preToolUse.parameters.content // empty')

if [[ -z "$content" ]]; then
  echo '{"cancel": false}'
  exit 0
fi

# Create temporary file for linting
temp_file=$(mktemp)
echo "$content" > "$temp_file"

# Run appropriate linter based on file extension
lint_errors=""
if [[ "$file_path" =~ \.(ts|tsx)$ ]] && command -v eslint > /dev/null; then
  lint_output=$(eslint "$temp_file" --format=json 2>/dev/null || true)
  if [[ "$lint_output" != "[]" ]] && [[ -n "$lint_output" ]]; then
    error_count=$(echo "$lint_output" | jq '.[0].errorCount // 0')
    if (( error_count > 0 )); then
      messages=$(echo "$lint_output" | jq -r '.[0].messages[] | "\(.line):\(.column) \(.message)"')
      lint_errors="ESLint errors found:\n$messages"
    fi
  fi
elif [[ "$file_path" =~ \.py$ ]] && command -v flake8 > /dev/null; then
  lint_output=$(flake8 "$temp_file" 2>/dev/null || true)
  if [[ -n "$lint_output" ]]; then
    lint_errors="Flake8 errors found:\n$lint_output"
  fi
fi

# Cleanup
rm -f "$temp_file"

# Block if linting errors found
if [[ -n "$lint_errors" ]]; then
  error_message="Code quality check failed. Please fix these issues:\n\n$lint_errors"
  jq -n --arg msg "$error_message" '{"cancel": true, "errorMessage": $msg}'
else
  echo '{"cancel": false}'
fi
```

## Security Enforcement

### Secrets Detection Hook

Prevent accidental commit of API keys, passwords, and other sensitive data.

**Hook:** `PreToolUse`

```bash
#!/usr/bin/env bash
input=$(cat)

tool_name=$(echo "$input" | jq -r '.preToolUse.toolName')

# Only check file operations
if [[ "$tool_name" != "write_to_file" ]]; then
  echo '{"cancel": false}'
  exit 0
fi

content=$(echo "$input" | jq -r '.preToolUse.parameters.content // empty')
file_path=$(echo "$input" | jq -r '.preToolUse.parameters.path // empty')

# Skip if no content
if [[ -z "$content" ]]; then
  echo '{"cancel": false}'
  exit 0
fi

# Define secret patterns
declare -a patterns=(
  "(?i)(api[_-]?key|apikey)\s*[:=]\s*['\"][a-zA-Z0-9_-]{10,}['\"]"
  "(?i)(secret|password|pwd)\s*[:=]\s*['\"][^'\"]{8,}['\"]"
  "(?i)token\s*[:=]\s*['\"][a-zA-Z0-9_-]{10,}['\"]"
  "(?i)(aws[_-]?access[_-]?key[_-]?id)\s*[:=]\s*['\"][A-Z0-9]{20}['\"]"
  "(?i)(aws[_-]?secret[_-]?access[_-]?key)\s*[:=]\s*['\"][a-zA-Z0-9+/]{40}['\"]"
  "sk-[a-zA-Z0-9]{20,50}"  # OpenAI API keys
  "ghp_[a-zA-Z0-9]{36}"    # GitHub personal access tokens
)

# Check for secrets
secrets_found=""
for pattern in "${patterns[@]}"; do
  if echo "$content" | grep -qP "$pattern"; then
    match=$(echo "$content" | grep -oP "$pattern" | head -1)
    secrets_found+="- Potential secret detected: ${match:0:20}...\n"
  fi
done

# Check for hardcoded private keys
if echo "$content" | grep -q "BEGIN.*PRIVATE KEY"; then
  secrets_found+="- Private key detected\n"
fi

# Allow secrets in certain safe files
safe_patterns=("\.env\.example$" "\.env\.template$" "/docs/" "/examples/" "\.md$")
is_safe_file=false
for safe_pattern in "${safe_patterns[@]}"; do
  if [[ "$file_path" =~ $safe_pattern ]]; then
    is_safe_file=true
    break
  fi
done

if [[ -n "$secrets_found" ]] && [[ "$is_safe_file" == false ]]; then
  error_message="ðŸ”’ SECURITY ALERT: Potential secrets detected in $file_path

$secrets_found
Please:
1. Use environment variables instead: process.env.API_KEY
2. Add sensitive files to .gitignore
3. Use a secrets management service
4. Consider using .env.example for documentation"

  jq -n --arg msg "$error_message" '{"cancel": true, "errorMessage": $msg}'
else
  echo '{"cancel": false}'
fi
```

### File Access Auditing Hook

Track and log all file access for compliance and security monitoring.

**Hook:** `PostToolUse`

```bash
#!/usr/bin/env bash
input=$(cat)

tool_name=$(echo "$input" | jq -r '.postToolUse.toolName')
success=$(echo "$input" | jq -r '.postToolUse.success')
timestamp=$(echo "$input" | jq -r '.timestamp')
task_id=$(echo "$input" | jq -r '.taskId')
user_id=$(echo "$input" | jq -r '.userId')

# Only log file operations
case "$tool_name" in
  "read_file"|"write_to_file"|"replace_in_file"|"list_files")
    ;;
  *)
    echo '{"cancel": false}'
    exit 0
    ;;
esac

# Extract file path
file_path=""
case "$tool_name" in
  "read_file"|"write_to_file"|"replace_in_file")
    file_path=$(echo "$input" | jq -r '.postToolUse.parameters.path // "unknown"')
    ;;
  "list_files")
    file_path=$(echo "$input" | jq -r '.postToolUse.parameters.path // "unknown"')
    ;;
esac

# Create audit log directory
audit_dir="$HOME/.cline_audit"
mkdir -p "$audit_dir"

# Log to daily audit file
audit_file="$audit_dir/$(date +%Y-%m-%d).log"

# Create detailed log entry
log_entry=$(jq -n \
  --arg timestamp "$timestamp" \
  --arg task_id "$task_id" \
  --arg user_id "$user_id" \
  --arg tool "$tool_name" \
  --arg path "$file_path" \
  --arg success "$success" \
  '{
    timestamp: $timestamp,
    task_id: $task_id, 
    user_id: $user_id,
    operation: $tool,
    file_path: $path,
    success: ($success == "true"),
    workspace: env.PWD
  }')

echo "$log_entry" >> "$audit_file"

# Alert on sensitive file access
sensitive_patterns=("\.env$" "\.key$" "\.pem$" "\.p12$" "config/" "secrets/")
is_sensitive=false
for pattern in "${sensitive_patterns[@]}"; do
  if [[ "$file_path" =~ $pattern ]]; then
    is_sensitive=true
    break
  fi
done

if [[ "$is_sensitive" == true ]]; then
  context="SECURITY_AUDIT: Sensitive file accessed: $file_path. This operation has been logged for compliance."
  jq -n --arg ctx "$context" '{"cancel": false, "contextModification": $ctx}'
else
  echo '{"cancel": false}'
fi
```

## Development Workflow Integration

### Git Integration Hook

Automatically create meaningful commit messages and enforce branch naming conventions.

**Hook:** `PostToolUse`

```bash
#!/usr/bin/env bash
input=$(cat)

tool_name=$(echo "$input" | jq -r '.postToolUse.toolName')
success=$(echo "$input" | jq -r '.postToolUse.success')

# Only process successful file modifications
if [[ "$success" != "true" ]] || [[ "$tool_name" != "write_to_file" && "$tool_name" != "replace_in_file" ]]; then
  echo '{"cancel": false}'
  exit 0
fi

# Check if we're in a git repository
if ! git rev-parse --git-dir > /dev/null 2>&1; then
  echo '{"cancel": false}'
  exit 0
fi

file_path=$(echo "$input" | jq -r '.postToolUse.parameters.path // empty')

# Skip if no file path
if [[ -z "$file_path" ]]; then
  echo '{"cancel": false}'
  exit 0
fi

# Check current branch
current_branch=$(git branch --show-current 2>/dev/null || echo "main")

# Suggest better branch naming for certain patterns
context=""
if [[ "$file_path" == *"component"* ]] && [[ "$current_branch" == "main" || "$current_branch" == "master" ]]; then
  context="GIT_WORKFLOW: Consider creating a feature branch for component changes: git checkout -b feature/add-${file_path##*/}"
elif [[ "$file_path" == *"test"* ]] || [[ "$file_path" == *"spec"* ]]; then
  if [[ "$current_branch" == "main" || "$current_branch" == "master" ]]; then
    context="GIT_WORKFLOW: Consider creating a test branch: git checkout -b test/add-${file_path##*/}-tests"
  fi
elif [[ "$file_path" == *"fix"* ]] || [[ "$file_path" == *"bug"* ]]; then
  if [[ "$current_branch" == "main" || "$current_branch" == "master" ]]; then
    context="GIT_WORKFLOW: Consider creating a bugfix branch: git checkout -b bugfix/fix-issue-description"
  fi
fi

# Stage the file automatically (optional - remove if you prefer manual staging)
# git add "$file_path" 2>/dev/null || true

# Add context about staging
if [[ -n "$context" ]]; then
  context="$context After your changes are complete, use 'git add $file_path' to stage for commit."
else
  context="GIT_WORKFLOW: File modified: $file_path. Use 'git add $file_path' to stage when ready to commit."
fi

jq -n --arg ctx "$context" '{"cancel": false, "contextModification": $ctx}'
```

### CI/CD Trigger Hook

Notify CI/CD systems and trigger builds when certain files are modified.

**Hook:** `PostToolUse`

```bash
#!/usr/bin/env bash
input=$(cat)

tool_name=$(echo "$input" | jq -r '.postToolUse.toolName')
success=$(echo "$input" | jq -r '.postToolUse.success')

# Only process successful file operations
if [[ "$success" != "true" ]] || [[ "$tool_name" != "write_to_file" && "$tool_name" != "replace_in_file" ]]; then
  echo '{"cancel": false}'
  exit 0
fi

file_path=$(echo "$input" | jq -r '.postToolUse.parameters.path // empty')

# Define trigger patterns for different workflows
declare -A triggers=(
  ["package\\.json|yarn\\.lock|package-lock\\.json"]="dependencies"
  ["\\.github/workflows/.*\\.ya?ml"]="workflow"
  ["Dockerfile|docker-compose\\.ya?ml"]="docker"
  ["src/.*\\.(ts|tsx|js|jsx)"]="frontend"
  ["api/.*\\.(ts|js|py)"]="backend"
  ["\\.(test|spec)\\.(ts|tsx|js|jsx|py)"]="tests"
)

# Check which workflows should be triggered
triggered_workflows=""
for pattern in "${!triggers[@]}"; do
  if [[ "$file_path" =~ $pattern ]]; then
    workflow_type="${triggers[$pattern]}"
    triggered_workflows+="$workflow_type "
  fi
done

if [[ -n "$triggered_workflows" ]]; then
  # Create webhook payload (example - adjust URL and payload as needed)
  webhook_url="${CI_WEBHOOK_URL:-}"
  
  if [[ -n "$webhook_url" ]]; then
    payload=$(jq -n \
      --arg file "$file_path" \
      --arg workflows "$triggered_workflows" \
      --arg timestamp "$(date -Iseconds)" \
      '{
        event: "file_modified",
        file_path: $file,
        triggered_workflows: ($workflows | split(" ") | map(select(length > 0))),
        timestamp: $timestamp,
        source: "cline_hook"
      }')
    
    # Trigger webhook asynchronously (don't block on network issues)
    curl -X POST \
      -H "Content-Type: application/json" \
      -d "$payload" \
      "$webhook_url" \
      --max-time 5 \
      --silent \
      > /dev/null 2>&1 &
  fi
  
  context="CI_CD: File modification may trigger workflows: $triggered_workflows. Check your CI/CD dashboard for build status."
  jq -n --arg ctx "$context" '{"cancel": false, "contextModification": $ctx}'
else
  echo '{"cancel": false}'
fi
```

## Performance Monitoring

### Operation Performance Tracker

Monitor and log slow operations to identify performance bottlenecks.

**Hook:** `PostToolUse`

```bash
#!/usr/bin/env bash
input=$(cat)

tool_name=$(echo "$input" | jq -r '.postToolUse.toolName')
execution_time=$(echo "$input" | jq -r '.postToolUse.executionTimeMs // 0')
success=$(echo "$input" | jq -r '.postToolUse.success')
timestamp=$(echo "$input" | jq -r '.timestamp')

# Performance thresholds (in milliseconds)
SLOW_THRESHOLD=2000
VERY_SLOW_THRESHOLD=5000

# Create performance log directory
perf_dir="$HOME/.cline_performance"
mkdir -p "$perf_dir"

# Log all operations to daily performance file
perf_file="$perf_dir/$(date +%Y-%m-%d).json"

# Create performance log entry
log_entry=$(jq -n \
  --arg timestamp "$timestamp" \
  --arg tool "$tool_name" \
  --arg duration "$execution_time" \
  --arg success "$success" \
  '{
    timestamp: $timestamp,
    tool: $tool,
    duration_ms: ($duration | tonumber),
    success: ($success == "true"),
    workspace: env.PWD
  }')

echo "$log_entry" >> "$perf_file"

# Generate context based on performance
context=""
if (( execution_time > VERY_SLOW_THRESHOLD )); then
  context="PERFORMANCE_ALERT: Very slow operation detected! $tool_name took ${execution_time}ms. Consider optimizing or investigating system resources."
elif (( execution_time > SLOW_THRESHOLD )); then
  context="PERFORMANCE_WARNING: Slow operation - $tool_name took ${execution_time}ms. Monitor for patterns."
fi

# Calculate daily statistics (simple version)
if [[ "$tool_name" == "execute_command" ]] && (( execution_time > SLOW_THRESHOLD )); then
  # For slow commands, add specific guidance
  context+=" For slow commands, consider using background processes or breaking into smaller steps."
fi

if [[ -n "$context" ]]; then
  jq -n --arg ctx "$context" '{"cancel": false, "contextModification": $ctx}'
else
  echo '{"cancel": false}'
fi
```

## External Integrations

### Slack Notifications Hook

Send notifications to Slack for important events and errors.

**Hook:** `PostToolUse`

```bash
#!/usr/bin/env bash
input=$(cat)

tool_name=$(echo "$input" | jq -r '.postToolUse.toolName')
success=$(echo "$input" | jq -r '.postToolUse.success')
result=$(echo "$input" | jq -r '.postToolUse.result // empty')

# Only notify on significant events or errors
notify_tools=("execute_command" "browser_action")
should_notify=false

for notify_tool in "${notify_tools[@]}"; do
  if [[ "$tool_name" == "$notify_tool" ]]; then
    should_notify=true
    break
  fi
done

# Also notify on any failures
if [[ "$success" == "false" ]]; then
  should_notify=true
fi

if [[ "$should_notify" != "true" ]]; then
  echo '{"cancel": false}'
  exit 0
fi

# Get Slack webhook URL from environment
slack_webhook="${SLACK_WEBHOOK_URL:-}"

if [[ -z "$slack_webhook" ]]; then
  echo '{"cancel": false}'
  exit 0
fi

# Determine message color and content
if [[ "$success" == "false" ]]; then
  color="danger"
  status_icon="ðŸš¨"
  title="Cline Operation Failed"
else
  color="good"
  status_icon="âœ…"
  title="Cline Operation Completed"
fi

# Create Slack message
user_id=$(echo "$input" | jq -r '.userId')
task_id=$(echo "$input" | jq -r '.taskId')
workspace=$(basename "$PWD")

# Truncate long results
truncated_result="$result"
if [[ ${#result} -gt 200 ]]; then
  truncated_result="${result:0:200}..."
fi

slack_payload=$(jq -n \
  --arg color "$color" \
  --arg title "$title" \
  --arg icon "$status_icon" \
  --arg tool "$tool_name" \
  --arg workspace "$workspace" \
  --arg result "$truncated_result" \
  --arg user "$user_id" \
  --arg task "$task_id" \
  '{
    attachments: [{
      color: $color,
      title: ($icon + " " + $title),
      fields: [
        {title: "Tool", value: $tool, short: true},
        {title: "Workspace", value: $workspace, short: true},
        {title: "User", value: $user, short: true},
        {title: "Task ID", value: $task, short: true},
        {title: "Result", value: $result, short: false}
      ],
      ts: now
    }]
  }')

# Send to Slack asynchronously
curl -X POST \
  -H "Content-Type: application/json" \
  -d "$slack_payload" \
  "$slack_webhook" \
  --max-time 5 \
  --silent \
  > /dev/null 2>&1 &

echo '{"cancel": false}'
```

### Jira Integration Hook

Create Jira tickets for errors and track development progress.

**Hook:** `TaskStart`

```bash
#!/usr/bin/env bash
input=$(cat)

initial_task=$(echo "$input" | jq -r '.taskStart.taskMetadata.initialTask')
task_id=$(echo "$input" | jq -r '.taskId')

# Get Jira configuration from environment
jira_url="${JIRA_URL:-}"
jira_user="${JIRA_USER:-}"
jira_token="${JIRA_TOKEN:-}"
jira_project="${JIRA_PROJECT:-DEV}"

if [[ -z "$jira_url" || -z "$jira_user" || -z "$jira_token" ]]; then
  echo '{"cancel": false}'
  exit 0
fi

# Determine if this looks like a bug fix or feature
issue_type="Task"
priority="Medium"

if echo "$initial_task" | grep -qi "bug\|fix\|error\|issue\|problem"; then
  issue_type="Bug"
  priority="High"
elif echo "$initial_task" | grep -qi "feature\|add\|implement\|create"; then
  issue_type="Story"
  priority="Medium"
fi

# Create Jira ticket payload
jira_payload=$(jq -n \
  --arg project "$jira_project" \
  --arg summary "Cline Task: $(echo "$initial_task" | head -c 100)" \
  --arg description "Automated task created from Cline:

**Task ID:** $task_id
**Full Description:** $initial_task
**Workspace:** $(basename "$PWD")
**Created:** $(date -Iseconds)

This ticket tracks development work performed by Cline AI assistant." \
  --arg issue_type "$issue_type" \
  --arg priority "$priority" \
  '{
    fields: {
      project: {key: $project},
      summary: $summary,
      description: $description,
      issuetype: {name: $issue_type},
      priority: {name: $priority},
      labels: ["cline", "automated", "ai-generated"]
    }
  }')

# Create Jira ticket
jira_response=$(curl -X POST \
  -H "Content-Type: application/json" \
  -u "$jira_user:$jira_token" \
  -d "$jira_payload" \
  "$jira_url/rest/api/2/issue/" \
  --max-time 10 \
  --silent)

# Extract ticket key if successful
ticket_key=$(echo "$jira_response" | jq -r '.key // empty' 2>/dev/null)

if [[ -n "$ticket_key" ]]; then
  context="JIRA_INTEGRATION: Created ticket $ticket_key for this task. Visit $jira_url/browse/$ticket_key to track progress."
  jq -n --arg ctx "$context" '{"cancel": false, "contextModification": $ctx}'
else
  echo '{"cancel": false}'
fi
```

## Task Lifecycle Management

### Task Completion Tracking Hook

Track successful task completions and generate completion reports.

**Hook:** `TaskComplete`

```bash
#!/usr/bin/env bash
input=$(cat)

task_id=$(echo "$input" | jq -r '.taskId')
initial_task=$(echo "$input" | jq -r '.taskComplete.taskMetadata.initialTask')
completion_time=$(echo "$input" | jq -r '.timestamp')
total_operations=$(echo "$input" | jq -r '.taskComplete.totalOperations // 0')
duration_minutes=$(echo "$input" | jq -r '.taskComplete.durationMinutes // 0')

# Create completion report directory
reports_dir="$HOME/.cline_reports"
mkdir -p "$reports_dir"

# Generate completion report
report_file="$reports_dir/completion_$(date +%Y%m%d_%H%M%S)_${task_id}.md"

cat > "$report_file" << EOF
# Cline Task Completion Report

**Task ID:** $task_id
**Completed:** $(date -Iseconds)
**Duration:** ${duration_minutes} minutes
**Total Operations:** $total_operations

## Task Description
$initial_task

## Workspace Information
- **Project:** $(basename "$PWD")
- **Git Branch:** $(git branch --show-current 2>/dev/null || echo "No git repository")
- **Git Status:** $(git status --porcelain 2>/dev/null | wc -l || echo "0") modified files

## Performance Metrics
- Average operations per minute: $(echo "scale=2; $total_operations / ($duration_minutes + 1)" | bc 2>/dev/null || echo "N/A")
- Completion status: âœ… Success

## Next Steps
- Review changes made during this task
- Consider committing changes: \`git add -A && git commit -m "Complete: ${initial_task:0:50}"\`
- Run tests to verify functionality
EOF

# Send completion notification if webhook configured
webhook_url="${COMPLETION_WEBHOOK_URL:-}"
if [[ -n "$webhook_url" ]]; then
  payload=$(jq -n \
    --arg task_id "$task_id" \
    --arg task "$initial_task" \
    --arg duration "$duration_minutes" \
    --arg operations "$total_operations" \
    --arg workspace "$(basename "$PWD")" \
    '{
      event: "task_completed",
      task_id: $task_id,
      description: $task,
      duration_minutes: ($duration | tonumber),
      total_operations: ($operations | tonumber),
      workspace: $workspace,
      timestamp: now | strftime("%Y-%m-%dT%H:%M:%SZ")
    }')
  
  curl -X POST \
    -H "Content-Type: application/json" \
    -d "$payload" \
    "$webhook_url" \
    --max-time 5 \
    --silent > /dev/null 2>&1 &
fi

# Provide completion summary
context="TASK_COMPLETED: âœ… Task finished successfully in ${duration_minutes} minutes with ${total_operations} operations. Report saved to: $report_file"

jq -n --arg ctx "$context" '{"cancel": false, "contextModification": $ctx}'
```

### Task Cancellation Handler Hook  

Handle task cancellations gracefully with cleanup and logging.

**Hook:** `TaskCancel`

```bash
#!/usr/bin/env bash
input=$(cat)

task_id=$(echo "$input" | jq -r '.taskId')
cancellation_reason=$(echo "$input" | jq -r '.taskCancel.reason // "User requested"')
partial_operations=$(echo "$input" | jq -r '.taskCancel.completedOperations // 0')
duration_minutes=$(echo "$input" | jq -r '.taskCancel.durationMinutes // 0')

# Create cancellation log directory
cancel_dir="$HOME/.cline_cancellations"
mkdir -p "$cancel_dir"

# Log cancellation details
cancel_log="$cancel_dir/$(date +%Y-%m-%d).log"

cancel_entry=$(jq -n \
  --arg timestamp "$(date -Iseconds)" \
  --arg task_id "$task_id" \
  --arg reason "$cancellation_reason" \
  --arg operations "$partial_operations" \
  --arg duration "$duration_minutes" \
  --arg workspace "$(basename "$PWD")" \
  '{
    timestamp: $timestamp,
    task_id: $task_id,
    reason: $reason,
    completed_operations: ($operations | tonumber),
    duration_minutes: ($duration | tonumber),
    workspace: $workspace
  }')

echo "$cancel_entry" >> "$cancel_log"

# Clean up temporary files created during this task
temp_patterns=("*.tmp" "*.temp" ".cline_*" "*_backup_*")
cleaned_files=0

for pattern in "${temp_patterns[@]}"; do
  if ls $pattern 1> /dev/null 2>&1; then
    rm -f $pattern 2>/dev/null || true
    ((cleaned_files++))
  fi
done

# Revert any uncommitted git changes if requested
if [[ "$cancellation_reason" == *"revert"* ]] && git rev-parse --git-dir > /dev/null 2>&1; then
  if [[ -n "$(git status --porcelain)" ]]; then
    git stash push -m "Auto-stash from canceled Cline task $task_id" > /dev/null 2>&1 || true
    context="TASK_CANCELED: Task $task_id canceled after ${duration_minutes}m and ${partial_operations} operations. Uncommitted changes stashed. Cleaned $cleaned_files temporary files."
  else
    context="TASK_CANCELED: Task $task_id canceled after ${duration_minutes}m and ${partial_operations} operations. No uncommitted changes found. Cleaned $cleaned_files temporary files."
  fi
else
  context="TASK_CANCELED: Task $task_id canceled after ${duration_minutes}m and ${partial_operations} operations. Reason: $cancellation_reason. Cleaned $cleaned_files temporary files."
fi

# Optional: Send cancellation alert
cancel_webhook="${CANCEL_WEBHOOK_URL:-}"
if [[ -n "$cancel_webhook" ]]; then
  payload=$(jq -n \
    --arg task_id "$task_id" \
    --arg reason "$cancellation_reason" \
    --arg operations "$partial_operations" \
    --arg duration "$duration_minutes" \
    '{
      event: "task_canceled",
      task_id: $task_id,
      reason: $reason,
      partial_operations: ($operations | tonumber),
      duration_minutes: ($duration | tonumber),
      timestamp: now | strftime("%Y-%m-%dT%H:%M:%SZ")
    }')
  
  curl -X POST \
    -H "Content-Type: application/json" \
    -d "$payload" \
    "$cancel_webhook" \
    --max-time 3 \
    --silent > /dev/null 2>&1 &
fi

jq -n --arg ctx "$context" '{"cancel": false, "contextModification": $ctx}'
```

### Task Resume Preparation Hook

Prepare environment and validate state when resuming tasks.

**Hook:** `TaskResume`

```bash
#!/usr/bin/env bash
input=$(cat)

task_id=$(echo "$input" | jq -r '.taskId')
original_task=$(echo "$input" | jq -r '.taskResume.taskMetadata.initialTask')
pause_duration=$(echo "$input" | jq -r '.taskResume.pauseDurationMinutes // 0')
last_operation=$(echo "$input" | jq -r '.taskResume.lastCompletedOperation // "unknown"')

# Validate workspace state
workspace_issues=""

# Check if git repository state changed
if git rev-parse --git-dir > /dev/null 2>&1; then
  # Check for new commits since pause
  current_branch=$(git branch --show-current 2>/dev/null || echo "")
  uncommitted_changes=$(git status --porcelain | wc -l)
  
  if (( uncommitted_changes > 5 )); then
    workspace_issues+="âš ï¸ Many uncommitted changes detected ($uncommitted_changes files). "
  fi
  
  # Check if branch switched
  expected_branch_file=".cline_task_${task_id}_branch"
  if [[ -f "$expected_branch_file" ]]; then
    expected_branch=$(cat "$expected_branch_file")
    if [[ "$current_branch" != "$expected_branch" ]]; then
      workspace_issues+="âš ï¸ Git branch changed from '$expected_branch' to '$current_branch'. "
    fi
  else
    # Store current branch for future reference
    echo "$current_branch" > "$expected_branch_file"
  fi
fi

# Check for dependency changes
dependency_issues=""
if [[ -f "package.json" ]]; then
  if [[ -f ".cline_task_${task_id}_package_hash" ]]; then
    stored_hash=$(cat ".cline_task_${task_id}_package_hash")
    current_hash=$(shasum package.json | cut -d' ' -f1)
    if [[ "$stored_hash" != "$current_hash" ]]; then
      dependency_issues+="âš ï¸ package.json modified during pause - dependencies may have changed. Consider running npm install. "
    fi
  else
    shasum package.json | cut -d' ' -f1 > ".cline_task_${task_id}_package_hash"
  fi
fi

# Check system resources
available_space=$(df . | tail -1 | awk '{print $4}')
if (( available_space < 1000000 )); then  # Less than ~1GB
  workspace_issues+="âš ï¸ Low disk space ($(echo $available_space | awk '{print $1/1000000 "GB"}'). "
fi

# Create resume context
context="TASK_RESUMED: Continuing task after ${pause_duration} minute pause. Last operation: $last_operation."

if [[ -n "$workspace_issues" ]]; then
  context="$context WORKSPACE_CHANGES: $workspace_issues"
fi

if [[ -n "$dependency_issues" ]]; then
  context="$context DEPENDENCY_CHANGES: $dependency_issues"
fi

# Log resume event
resume_log="$HOME/.cline_resumes/$(date +%Y-%m-%d).log"
mkdir -p "$(dirname "$resume_log")"

resume_entry=$(jq -n \
  --arg timestamp "$(date -Iseconds)" \
  --arg task_id "$task_id" \
  --arg pause_duration "$pause_duration" \
  --arg last_op "$last_operation" \
  --arg workspace_issues "$workspace_issues" \
  '{
    timestamp: $timestamp,
    task_id: $task_id,
    pause_duration_minutes: ($pause_duration | tonumber),
    last_operation: $last_op,
    workspace_issues: $workspace_issues,
    workspace: env.PWD
  }')

echo "$resume_entry" >> "$resume_log"

jq -n --arg ctx "$context" '{"cancel": false, "contextModification": $ctx}'
```

## Memory and Context Management

### Pre-Compact Context Preservation Hook

Backup important conversation context before history compaction.

**Hook:** `PreCompact`

```bash
#!/usr/bin/env bash
input=$(cat)

task_id=$(echo "$input" | jq -r '.taskId')
messages_to_remove=$(echo "$input" | jq -r '.preCompact.messagesToRemove // 0')
total_messages=$(echo "$input" | jq -r '.preCompact.totalMessages // 0')
compaction_trigger=$(echo "$input" | jq -r '.preCompact.trigger // "context_limit"')

# Create context backup directory
backup_dir="$HOME/.cline_context_backups"
mkdir -p "$backup_dir"

# Create dated backup file
backup_file="$backup_dir/${task_id}_$(date +%Y%m%d_%H%M%S).json"

# Extract conversation history for backup
conversation_history=$(echo "$input" | jq '.preCompact.conversationHistory // []')

# Create comprehensive backup
backup_data=$(jq -n \
  --arg task_id "$task_id" \
  --arg timestamp "$(date -Iseconds)" \
  --arg trigger "$compaction_trigger" \
  --arg messages_removed "$messages_to_remove" \
  --arg total_messages "$total_messages" \
  --argjson history "$conversation_history" \
  '{
    task_id: $task_id,
    backup_timestamp: $timestamp,
    compaction_trigger: $trigger,
    messages_removed: ($messages_removed | tonumber),
    total_messages: ($total_messages | tonumber),
    workspace: env.PWD,
    git_commit: null,
    conversation_history: $history
  }')

# Add git commit hash if available
if git rev-parse --git-dir > /dev/null 2>&1; then
  git_hash=$(git rev-parse HEAD 2>/dev/null || echo "no-commit")
  backup_data=$(echo "$backup_data" | jq --arg hash "$git_hash" '.git_commit = $hash')
fi

echo "$backup_data" > "$backup_file"

# Compress older backups (keep last 5 uncompressed)
find "$backup_dir" -name "${task_id}_*.json" -type f | sort -r | tail -n +6 | while read old_backup; do
  if [[ ! -f "${old_backup}.gz" ]]; then
    gzip "$old_backup" 2>/dev/null || true
  fi
done

# Extract key information for context preservation
important_context=""

# Look for error patterns in history
if echo "$conversation_history" | jq -r '.[] | select(.type == "error") | .content' | grep -q .; then
  error_count=$(echo "$conversation_history" | jq '[.[] | select(.type == "error")] | length')
  important_context+="Previous errors encountered: $error_count. "
fi

# Look for successful patterns
if echo "$conversation_history" | jq -r '.[] | select(.type == "success") | .content' | grep -q .; then
  success_patterns=$(echo "$conversation_history" | jq -r '[.[] | select(.type == "success")] | length')
  important_context+="Successful operations: $success_patterns. "
fi

# Create context summary for AI
context="CONTEXT_COMPACTION: Removing $messages_to_remove of $total_messages messages due to $compaction_trigger. Backup saved to: $(basename "$backup_file"). "

if [[ -n "$important_context" ]]; then
  context+="PRESERVED_CONTEXT: $important_context"
fi

# Optional: Send to external storage
external_backup_webhook="${CONTEXT_BACKUP_WEBHOOK:-}"
if [[ -n "$external_backup_webhook" ]]; then
  curl -X POST \
    -H "Content-Type: application/json" \
    -d "$backup_data" \
    "$external_backup_webhook" \
    --max-time 10 \
    --silent > /dev/null 2>&1 &
fi

jq -n --arg ctx "$context" '{"cancel": false, "contextModification": $ctx}'
```

### User Input Validation Hook

Validate and enhance user prompts before processing.

**Hook:** `UserPromptSubmit`

```bash
#!/usr/bin/env bash
input=$(cat)

user_prompt=$(echo "$input" | jq -r '.userPromptSubmit.prompt')
prompt_type=$(echo "$input" | jq -r '.userPromptSubmit.type // "text"')
task_id=$(echo "$input" | jq -r '.taskId')
user_id=$(echo "$input" | jq -r '.userId')

# Log user activity for analytics
activity_log="$HOME/.cline_user_activity/$(date +%Y-%m-%d).log"
mkdir -p "$(dirname "$activity_log")"

activity_entry=$(jq -n \
  --arg timestamp "$(date -Iseconds)" \
  --arg task_id "$task_id" \
  --arg user_id "$user_id" \
  --arg prompt_length "${#user_prompt}" \
  --arg prompt_type "$prompt_type" \
  '{
    timestamp: $timestamp,
    task_id: $task_id,
    user_id: $user_id,
    prompt_length: ($prompt_length | tonumber),
    prompt_type: $prompt_type,
    workspace: env.PWD
  }')

echo "$activity_entry" >> "$activity_log"

# Analyze prompt for potential issues
context_modifications=""
cancel_request=false

# Check for potentially harmful requests
harmful_patterns=("rm -rf" "delete" "remove all" "format.*drive" "sudo.*passwd")
for pattern in "${harmful_patterns[@]}"; do
  if echo "$user_prompt" | grep -qi "$pattern"; then
    cancel_request=true
    error_message="ðŸš¨ SAFETY ALERT: Potentially harmful command detected in prompt. Please review your request and ensure it's safe to execute."
    break
  fi
done

# Enhance prompts with helpful context
if [[ "$cancel_request" == false ]]; then
  # Add project context if user asks about files
  if echo "$user_prompt" | grep -qi "file\|directory\|folder" && [[ ! "$user_prompt" == *"context:"* ]]; then
    if [[ -f "package.json" ]]; then
      project_name=$(jq -r '.name // "unknown"' package.json 2>/dev/null)
      context_modifications+="PROJECT_CONTEXT: Working in Node.js project '$project_name'. "
    elif [[ -f "requirements.txt" ]] || [[ -f "setup.py" ]]; then
      context_modifications+="PROJECT_CONTEXT: Working in Python project. "
    elif [[ -f "Cargo.toml" ]]; then
      project_name=$(grep '^name = ' Cargo.toml | cut -d'"' -f2 2>/dev/null || echo "unknown")
      context_modifications+="PROJECT_CONTEXT: Working in Rust project '$project_name'. "
    fi
  fi
  
  # Add git context for version control related requests
  if echo "$user_prompt" | grep -qi "git\|commit\|branch\|merge" && git rev-parse --git-dir > /dev/null 2>&1; then
    current_branch=$(git branch --show-current 2>/dev/null)
    uncommitted=$(git status --porcelain | wc -l)
    context_modifications+="GIT_CONTEXT: On branch '$current_branch' with $uncommitted uncommitted changes. "
  fi
  
  # Suggest specific tools for common requests
  if echo "$user_prompt" | grep -qi "search.*code\|find.*function"; then
    context_modifications+="TOOL_SUGGESTION: Consider using search_files tool for code exploration. "
  elif echo "$user_prompt" | grep -qi "test.*website\|check.*browser"; then
    context_modifications+="TOOL_SUGGESTION: Consider using browser_action tool for web testing. "
  fi
  
  # Flag overly broad requests
  if (( ${#user_prompt} < 20 )) && echo "$user_prompt" | grep -qi "^(fix|update|change|modify)"; then
    context_modifications+="CLARITY_NEEDED: Request seems broad. Consider providing more specific details about what needs to be fixed/updated. "
  fi
fi

# Return appropriate response
if [[ "$cancel_request" == true ]]; then
  jq -n --arg msg "$error_message" '{"cancel": true, "errorMessage": $msg}'
else
  if [[ -n "$context_modifications" ]]; then
    jq -n --arg ctx "$context_modifications" '{"cancel": false, "contextModification": $ctx}'
  else
    echo '{"cancel": false}'
  fi
fi
```

## Usage Tips

### Running Multiple Hooks

You can use multiple hooks together by creating separate files for each hook type:

```bash
# Create hooks directory
mkdir -p .clinerules/hooks

# Create multiple hooks
touch .clinerules/hooks/PreToolUse
touch .clinerules/hooks/PostToolUse
touch .clinerules/hooks/TaskStart

# Make them executable
chmod +x .clinerules/hooks/*
```

### Environment Configuration

Set up environment variables for external integrations:

```bash
# Add to your .bashrc or .zshrc
export SLACK_WEBHOOK_URL="https://hooks.slack.com/services/..."
export JIRA_URL="https://yourcompany.atlassian.net"
export JIRA_USER="your-email@company.com"
export JIRA_TOKEN="your-api-token"
export CI_WEBHOOK_URL="https://your-ci-system.com/hooks/cline"
```

### Testing Your Hooks

Test hooks manually by simulating their input:

```bash
# Test a PreToolUse hook
echo '{
  "clineVersion": "1.0.0",
  "hookName": "PreToolUse",
  "timestamp": "2024-01-01T12:00:00Z",
  "taskId": "test",
  "workspaceRoots": ["/path/to/workspace"],
  "userId": "test-user",
  "preToolUse": {
    "toolName": "write_to_file",
    "parameters": {
      "path": "test.js",
      "content": "console.log(\"test\");"
    }
  }
}' | .clinerules/hooks/PreToolUse
```

These examples provide a solid foundation for implementing hooks in your development workflow. Customize them based on your specific needs, tools, and integrations.
