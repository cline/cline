---
title: "SAP AI Core"
description: "Learn how to configure and use LLM models from Generative AI Hub in SAP AI Core with Cline."
---

SAP AI Core and the generative AI hub help you to integrate LLMs and AI into new business processes in a cost-efficient manner.

**Website:** [SAP Help Portal](https://help.sap.com/docs/sap-ai-core/sap-ai-core-service-guide/what-is-sap-ai-core)


<Info>
SAP AI Core, and Generative AI Hub, are offerings from SAP BTP. You need an active SAP BTP contract and a existing subaccount with a SAP AI Core instance with the `extended` service plan (For more details about SAP AI Core service plans and their capabilities, see the [Service Plans documentation](https://help.sap.com/docs/sap-ai-core/sap-ai-core-service-guide/service-plans)) to perform these steps.
</Info>

### Getting a Service Binding

1. **Access:** Go to your subaccount via [BTP Cloud Cockpit](https://cockpit.btp.cloud.sap/cockpit)
2. **Create a Service Binding:** Go to "Instances and Subscriptions", select your SAP AI Core service instance and click on Service Bindings > Create.
3. **Copy the Service Binding:** Copy the service binding values.

### Supported Models

SAP AI Core supports a large and growing number of models.
Refer to the [Generative AI Hub Supported Models page](https://me.sap.com/notes/3437766) for the complete and up-to-date list.

### Configuration in Cline

1.  **Open Cline Settings:** Click the settings icon (⚙️) in the Cline panel.
2.  **Select Provider:** Choose "SAP AI Core" from the "API Provider" dropdown.
3.  **Enter Client Id:** Add the `.clientid` field from the service binding into the "AI Core Client Id" field.
4.  **Enter Client Secret:** Add the `.clientsecret` field from the service binding into the "AI Core Client Secret" field.
5.  **Enter Base URL:** Add the `.serviceurls.AI_API_URL` field from the service binding into the "AI Core Base URL" field.
6.  **Enter Auth URL:** Add the `.url` field from the service binding into the "AI Core Auth URL" field.
7.  **Enter Resource Group:** Add the resource group where you have your model deployments. See [Create a Deployment for a Generative AI Model](https://help.sap.com/docs/sap-ai-core/sap-ai-core-service-guide/create-deployment-for-generative-ai-model-in-sap-ai-core).
8.  **Configure Orchestration Mode:** If you have an `extended` service plan, the "Orchestration Mode" checkbox will automatically appear.
9.  **Select Model:** Choose your desired model from the "Model" dropdown.

### Orchestration Mode vs Native API

**Orchestration Mode:**
- **Simplified usage:** Provides access to all available models without requiring individual deployments using the [Harmonized API](https://help.sap.com/docs/sap-ai-core/sap-ai-core-service-guide/harmonized-api)

**Native API Mode:**
- **Manual deployments:** Requires manual model deployment and management in your SAP AI Core service instance

### Tips and Notes

- **Service Plan Requirement:** You must have the SAP AI Core `extended` service plan to use LLMs with Cline. Other service plans do not provide access to Generative AI Hub.

- **Orchestration Mode (Recommended):** Keep Orchestration Mode enabled for the simplest setup. It provides automatic access to all available models without requiring manual deployments.

- **Native API Mode:** Only disable Orchestration Mode if you have specific requirements that necessitate direct AI Core API access or need features not supported by the orchestration mode.

- **When using Native API Mode:**
    -   **Model Selection:** The model dropdown displays models in two separate lists:
        -   **Deployed Models:** These models are already deployed in your specified resource group and are ready to use immediately.
        -   **Not Deployed Models:** These models don't have active deployments in your specified resource group. You won't be able to use these models until you create deployments for them in SAP AI Core.
    -   **Creating Deployments:** To use a model that has not been deployed yet, you'll need to create a deployment in your SAP AI Core service instance. See [Create a Deployment for a Generative AI Model](https://help.sap.com/docs/sap-ai-core/sap-ai-core-service-guide/create-deployment-for-generative-ai-model-in-sap-ai-core) for instructions.

#### Configuring Reasoning Effort for OpenAI Models

When using OpenAI reasoning models (such as o1, o3, o3-mini, o4-mini) through SAP AI Core, you can control the reasoning effort to balance performance and cost:

1. **Open Cline Settings:** Click the settings icon (⚙️) in the Cline panel.
2. **Navigate to Features:** Go to the "Features" section in the settings.
3. **Find OpenAI Reasoning Effort:** Locate the "OpenAI Reasoning Effort" setting.
4. **Choose Effort Level:** Select between:
   - **Low:** Faster responses with lower token usage, suitable for simpler tasks
   - **Medium:** Balanced performance and token usage for most tasks
   - **High:** More thorough analysis with higher token usage, better for complex reasoning tasks

<Note>
This setting only applies when using OpenAI reasoning models (o1, o3, o3-mini, o4-mini, gpt-5, etc.) deployed through SAP AI Core. Other models will ignore this setting.
</Note>
