---
title: "xAI (Grok)"
description: "Learn how to configure and use xAI's Grok models with Cline, including API key setup, supported models, and reasoning capabilities."
---

xAI is the company behind Grok, a large language model known for its conversational abilities and large context window. Grok models are designed to provide helpful, informative, and contextually relevant responses.

**Website:** [https://x.ai/](https://x.ai/)

### Getting an API Key

1.  **Sign Up/Sign In:** Go to the [xAI Console](https://console.x.ai/). Create an account or sign in.
2.  **Navigate to API Keys:** Go to the API keys section in your dashboard.
3.  **Create a Key:** Click to create a new API key. Give your key a descriptive name (e.g., "Cline").
4.  **Copy the Key:** **Important:** Copy the API key _immediately_. You will not be able to see it again. Store it securely.

### Supported Models

Cline supports the following xAI Grok models:

#### Grok-4 Models

-   `grok-4` (Default) - xAI's flagship model with 262K context, prompt caching, and image support
-   `grok-4-fast-reasoning` - Fast reasoning variant with 2M context window
-   `grok-4-1-fast-reasoning` - Grok 4.1 fast reasoning with 2M context
-   `grok-4-1-fast-non-reasoning` - Grok 4.1 fast non-reasoning with 2M context and image support
-   `grok-code-fast-1` - Specialized coding model with 256K context

#### Grok-3 Models

-   `grok-3` - Grok-3 model with 131K context window
-   `grok-3-fast` - Grok-3 fast model with 131K context window
-   `grok-3-mini` - Grok-3 mini model with 131K context window
-   `grok-3-mini-fast` - Grok-3 mini fast model with 131K context window
-   `grok-3-beta` - Grok-3 beta model with 131K context window
-   `grok-3-fast-beta` - Grok-3 fast beta model with 131K context window
-   `grok-3-mini-beta` - Grok-3 mini beta model with 131K context window
-   `grok-3-mini-fast-beta` - Grok-3 mini fast beta model with 131K context window

#### Grok-2 Models

-   `grok-2-latest` - Grok-2 model - latest version with 131K context window
-   `grok-2` - Grok-2 model with 131K context window
-   `grok-2-1212` - Grok-2 model (version 1212) with 131K context window

#### Grok Vision Models

-   `grok-2-vision-latest` - Grok-2 Vision model - latest version with image support and 32K context window
-   `grok-2-vision` - Grok-2 Vision model with image support and 32K context window
-   `grok-2-vision-1212` - Grok-2 Vision model (version 1212) with image support and 32K context window
-   `grok-vision-beta` - Grok Vision Beta model with image support and 8K context window

#### Legacy Models

-   `grok-beta` - Grok Beta model (legacy) with 131K context window

### Configuration in Cline

1.  **Open Cline Settings:** Click the settings icon (⚙️) in the Cline panel.
2.  **Select Provider:** Choose "xAI" from the "API Provider" dropdown.
3.  **Enter API Key:** Paste your xAI API key into the "xAI API Key" field.
4.  **Select Model:** Choose your desired Grok model from the "Model" dropdown.

### Reasoning Capabilities

Grok 3 Mini models feature specialized reasoning capabilities, allowing them to "think before responding" - particularly useful for complex problem-solving tasks.

#### Reasoning-Enabled Models

Reasoning is only supported by:

-   `grok-3-mini-beta`
-   `grok-3-mini-fast-beta`

The Grok 3 models `grok-3-beta` and `grok-3-fast-beta` do not support reasoning.

#### Controlling Reasoning Effort

When using reasoning-enabled models, you can control how hard the model thinks with the `reasoning_effort` parameter:

-   `low`: Minimal thinking time, using fewer tokens for quick responses
-   `high`: Maximum thinking time, leveraging more tokens for complex problems

Choose `low` for simple queries that should complete quickly, and `high` for harder problems where response latency is less important.

#### Key Features

-   **Step-by-Step Problem Solving**: The model thinks through problems methodically before delivering an answer
-   **Math & Quantitative Strength**: Excels at numerical challenges and logic puzzles
-   **Reasoning Trace Access**: The model's thinking process is available via the `reasoning_content` field in the response completion object

### Tips and Notes

-   **Context Window:** Most Grok models feature large context windows (up to 131K tokens), allowing you to include substantial amounts of code and context in your prompts.
-   **Vision Capabilities:** Select vision-enabled models (`grok-2-vision-latest`, `grok-2-vision`, etc.) when you need to process or analyze images.
-   **Pricing:** Pricing varies by model, with input costs ranging from $0.3 to $5.0 per million tokens and output costs from $0.5 to $25.0 per million tokens. Refer to the xAI documentation for the most current pricing information.
-   **Performance Tradeoffs:** "Fast" variants typically offer quicker response times but may have higher costs, while "mini" variants are more economical but may have reduced capabilities.
