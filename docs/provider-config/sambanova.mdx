---
title: "SambaNova"
description: "Learn how to configure and use SambaNova's fast inference with Cline. Access Meta Llama, DeepSeek, and Qwen models on SambaNova's custom hardware."
---

SambaNova provides fast AI inference on custom-built hardware, hosting popular open-source models from Meta, DeepSeek, Qwen, and others.

**Website:** [https://sambanova.ai/](https://sambanova.ai/)

### Getting an API Key

1.  **Sign Up/Sign In:** Go to [SambaNova Cloud](https://cloud.sambanova.ai/). Create an account or sign in.
2.  **Navigate to API Keys:** Access the API key section in your dashboard.
3.  **Create a Key:** Generate a new API key.
4.  **Copy the Key:** Copy the API key immediately and store it securely.

### Supported Models

Cline supports the following SambaNova models:

#### Meta Llama Models
-   `Llama-4-Maverick-17B-128E-Instruct` - Llama 4 Maverick with vision support ($0.63/$1.80 per 1M tokens)
-   `Llama-4-Scout-17B-16E-Instruct` - Llama 4 Scout ($0.40/$0.70 per 1M tokens)
-   `Meta-Llama-3.3-70B-Instruct` (Default) - Versatile 70B model with 128K context ($0.60/$1.20 per 1M tokens)
-   `Meta-Llama-3.1-405B-Instruct` - Largest Llama model ($5.00/$10.00 per 1M tokens)
-   `Meta-Llama-3.1-8B-Instruct` - Compact 8B model ($0.10/$0.20 per 1M tokens)
-   `Meta-Llama-3.2-1B-Instruct` - Ultra-compact 1B model ($0.04/$0.08 per 1M tokens)
-   `Meta-Llama-3.2-3B-Instruct` - Small 3B model ($0.08/$0.16 per 1M tokens)

#### DeepSeek Models
-   `DeepSeek-R1` - Reasoning model ($5.00/$7.00 per 1M tokens)
-   `DeepSeek-R1-Distill-Llama-70B` - Distilled reasoning model ($0.70/$1.40 per 1M tokens)
-   `DeepSeek-V3-0324` - General-purpose model ($3.00/$4.50 per 1M tokens)
-   `DeepSeek-V3.1` - Latest DeepSeek with hybrid reasoning ($3.00/$4.50 per 1M tokens)

#### Qwen Models
-   `Qwen3-32B` - Dense 32B model ($0.40/$0.80 per 1M tokens)
-   `QwQ-32B` - Reasoning-focused Qwen model ($0.50/$1.00 per 1M tokens)

### Configuration in Cline

1.  **Open Cline Settings:** Click the settings icon (⚙️) in the Cline panel.
2.  **Select Provider:** Choose "SambaNova" from the "API Provider" dropdown.
3.  **Enter API Key:** Paste your SambaNova API key.
4.  **Select Model:** Choose your desired model from the "Model" dropdown.

### Tips and Notes

-   **Fast Inference:** SambaNova's custom hardware delivers competitive inference speeds.
-   **Wide Model Selection:** Access models from Meta, DeepSeek, and Qwen on a single platform.
-   **Pricing:** Check the [SambaNova documentation](https://docs.sambanova.ai/cloud/docs/get-started/supported-models) for current pricing.
