---
title: "Hugging Face"
description: "Learn how to configure and use Hugging Face Inference Providers with Cline. Access open-source models with free inference through the Hugging Face ecosystem."
---

Hugging Face provides inference access to popular open-source models through their Inference Providers ecosystem. Many models are available for free, making it an excellent option for experimentation and budget-conscious development.

**Website:** [https://huggingface.co/](https://huggingface.co/)

### Getting an API Key

1.  **Sign Up/Sign In:** Go to [Hugging Face](https://huggingface.co/). Create an account or sign in.
2.  **Navigate to Settings:** Go to your [Access Tokens](https://huggingface.co/settings/tokens) page.
3.  **Create a Token:** Generate a new access token with appropriate permissions.
4.  **Copy the Token:** Copy the token immediately and store it securely.

### Supported Models

Cline supports the following Hugging Face models (all currently free):

-   `moonshotai/Kimi-K2-Instruct` (Default) - Advanced reasoning model with 131K context, superior coding and math capabilities
-   `openai/gpt-oss-120b` - Large 120B open-weight reasoning model for complex tasks (131K context)
-   `openai/gpt-oss-20b` - Medium 20B open-weight model balancing reasoning with accessibility (131K context)
-   `deepseek-ai/DeepSeek-V3-0324` - Advanced reasoning model (64K context)
-   `deepseek-ai/DeepSeek-R1` - DeepSeek's reasoning model with step-by-step thinking (64K context)
-   `deepseek-ai/DeepSeek-R1-0528` - Latest DeepSeek reasoning version (64K context)
-   `meta-llama/Llama-3.1-8B-Instruct` - Efficient 8B Llama model for general tasks (128K context)

### Configuration in Cline

1.  **Open Cline Settings:** Click the settings icon (⚙️) in the Cline panel.
2.  **Select Provider:** Choose "Hugging Face" from the "API Provider" dropdown.
3.  **Enter Token:** Paste your Hugging Face access token.
4.  **Select Model:** Choose your desired model from the "Model" dropdown.

### Tips and Notes

-   **Free Inference:** All listed models are currently available at no cost through Hugging Face Inference Providers.
-   **Open Source:** All models are open-source and can also be self-hosted.
-   **Rate Limits:** Free tier has rate limits. Check Hugging Face documentation for current limits.
-   **Model Availability:** Model availability depends on inference provider capacity and may vary.
